#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ›´æ–°å…è´¹èŠ‚ç‚¹é…ç½®æ–‡ä»¶
ä» node.txt è¯»å– URLï¼Œä¸‹è½½å†…å®¹å¹¶å†™å…¥æ–°æ–‡ä»¶
"""

import requests
import yaml
import base64
from datetime import datetime
from pathlib import Path

# é…ç½®
SOURCES_FILE = "node.txt"
OUTPUT_DIR = "output"
OUTPUT_FILE = f"{OUTPUT_DIR}/node_content.txt"
CLASH_OUTPUT_FILE = f"{OUTPUT_DIR}/clash.yml"
TIMEOUT = 30

def read_sources():
    """ä» node.txt è¯»å–èŠ‚ç‚¹æº URL"""
    sources_file = Path(SOURCES_FILE)
    if not sources_file.exists():
        print(f"âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {SOURCES_FILE}")
        return []
    
    with open(sources_file, 'r', encoding='utf-8') as f:
        sources = [line.strip() for line in f if line.strip() and line.startswith('http')]
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(sources)} ä¸ªé…ç½®æº")
    return sources

def download_config(url):
    """ä¸‹è½½é…ç½®æ–‡ä»¶å†…å®¹"""
    try:
        print(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½: {url}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=TIMEOUT)
        response.raise_for_status()
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {len(response.text)} å­—èŠ‚")
        return response.text
    except requests.exceptions.Timeout:
        print(f"â±ï¸  ä¸‹è½½è¶…æ—¶: {url}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return None

def is_clash_config(content):
    """åˆ¤æ–­æ˜¯å¦ä¸º Clash é…ç½®"""
    try:
        data = yaml.safe_load(content)
        return isinstance(data, dict) and ('proxies' in data or 'proxy-groups' in data)
    except:
        return False

def extract_content(content):
    """æå–å¹¶å¤„ç†å†…å®¹"""
    if not content:
        return None, None
    
    clash_data = None
    
    # å¦‚æœæ˜¯ YAML æ ¼å¼ï¼ˆClash é…ç½®ï¼‰
    if is_clash_config(content):
        try:
            clash_data = yaml.safe_load(content)
        except:
            pass
    
    # å°è¯•è§£ç  Base64
    try:
        decoded = base64.b64decode(content.strip()).decode('utf-8')
        # å¦‚æœè§£ç æˆåŠŸä¸”åŒ…å«èŠ‚ç‚¹ä¿¡æ¯ï¼Œè¿”å›è§£ç åçš„å†…å®¹
        if any(protocol in decoded for protocol in ['vmess://', 'vless://', 'ss://', 'trojan://', 'http://', 'https://']):
            return decoded, clash_data
    except:
        pass
    
    # ç›´æ¥è¿”å›åŸå§‹å†…å®¹
    return content, clash_data

def merge_clash_configs(clash_configs):
    """åˆå¹¶æ‰€æœ‰ Clash é…ç½®"""
    if not clash_configs:
        return None
    
    # åˆ›å»ºåˆå¹¶åçš„é…ç½®ç»“æ„
    merged = {
        'proxies': [],
        'proxy-groups': [
            {
                'name': 'auto',
                'type': 'url-test',
                'proxies': [],
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300
            },
            {
                'name': 'PROXY',
                'type': 'select',
                'proxies': ['auto']
            }
        ],
        'rules': [
            'MATCH,PROXY'
        ]
    }
    
    proxy_names = []
    
    # åˆå¹¶æ‰€æœ‰ä»£ç†èŠ‚ç‚¹
    for clash_data in clash_configs:
        if 'proxies' in clash_data and isinstance(clash_data['proxies'], list):
            for proxy in clash_data['proxies']:
                if isinstance(proxy, dict) and 'name' in proxy:
                    # ç¡®ä¿èŠ‚ç‚¹åç§°å”¯ä¸€
                    original_name = proxy['name']
                    name = original_name
                    counter = 1
                    while name in proxy_names:
                        name = f"{original_name}_{counter}"
                        counter += 1
                    
                    proxy['name'] = name
                    proxy_names.append(name)
                    merged['proxies'].append(proxy)
    
    # æ›´æ–°ä»£ç†ç»„
    if proxy_names:
        merged['proxy-groups'][0]['proxies'] = proxy_names.copy()
        merged['proxy-groups'][1]['proxies'].insert(0, 'auto')
        merged['proxy-groups'][1]['proxies'].extend(proxy_names)
    
    return merged

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print(f"ğŸš€ å¼€å§‹ä» {SOURCES_FILE} æå–å†…å®¹")
    print(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # è¯»å–é…ç½®æº
    sources = read_sources()
    if not sources:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„é…ç½®æº")
        return
    
    # å­˜å‚¨æ‰€æœ‰ä¸‹è½½çš„å†…å®¹
    all_contents = []
    clash_configs = []
    success_count = 0
    fail_count = 0
    
    # ä¸‹è½½å¹¶æå–å†…å®¹
    for i, url in enumerate(sources, 1):
        print(f"\n{'â”€'*60}")
        print(f"[{i}/{len(sources)}] å¤„ç†: {url}")
        
        content = download_config(url)
        
        if content:
            extracted, clash_data = extract_content(content)
            
            if extracted:
                # æ”¶é›† Clash é…ç½®
                if clash_data:
                    clash_configs.append(clash_data)
                    print(f"ğŸ“¦ å‘ç° Clash é…ç½® - å°†å†™å…¥ clash.yml")
                else:
                    # åªæœ‰é Clash å†…å®¹æ‰å†™å…¥ node_content.txtï¼ˆçº¯å†…å®¹ï¼Œæ— æ³¨é‡Šï¼‰
                    all_contents.append(extracted)
                    print(f"âœ… å†…å®¹å·²åŠ å…¥ node_content.txt")
                
                success_count += 1
            else:
                fail_count += 1
                print(f"âš ï¸  å†…å®¹æå–å¤±è´¥")
        else:
            fail_count += 1
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    
    # å†™å…¥æ‰€æœ‰å†…å®¹åˆ° node_content.txtï¼ˆåˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼ŒæŒ‰è¡Œåˆ†éš”ï¼‰
    if all_contents:
        output_path = Path(OUTPUT_FILE)
        # åˆå¹¶æ‰€æœ‰å†…å®¹ï¼Œæ¯ä¸ªå†…å®¹çš„è¡Œåˆå¹¶åœ¨ä¸€èµ·
        all_lines = []
        for content in all_contents:
            lines = content.strip().split('\n')
            all_lines.extend(lines)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_lines))
        print(f"\nğŸ’¾ æ‰€æœ‰å†…å®¹å·²å†™å…¥: {OUTPUT_FILE} ({output_path.stat().st_size} å­—èŠ‚)")
    
    # åˆå¹¶å¹¶ä¿å­˜ Clash é…ç½®
    if clash_configs:
        print(f"\n{'â”€'*60}")
        print(f"ğŸ”— å¼€å§‹åˆå¹¶ Clash é…ç½®...")
        merged_clash = merge_clash_configs(clash_configs)
        
        if merged_clash and merged_clash['proxies']:
            clash_path = Path(CLASH_OUTPUT_FILE)
            with open(clash_path, 'w', encoding='utf-8') as f:
                yaml.dump(merged_clash, f, allow_unicode=True, sort_keys=False)
            
            print(f"âœ… Clash é…ç½®å·²åˆå¹¶")
            print(f"   èŠ‚ç‚¹æ€»æ•°: {len(merged_clash['proxies'])}")
            print(f"   æ–‡ä»¶å¤§å°: {clash_path.stat().st_size} å­—èŠ‚")
            print(f"   ä¿å­˜ä½ç½®: {CLASH_OUTPUT_FILE}")
        else:
            print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ Clash èŠ‚ç‚¹")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»æºæ•°: {len(sources)}")
    print(f"   æˆåŠŸ: {success_count}")
    print(f"   å¤±è´¥: {fail_count}")
    print(f"   Clash é…ç½®: {len(clash_configs)} ä¸ª")
    print("="*60)

if __name__ == "__main__":
    main()