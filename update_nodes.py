#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ›´æ–°å…è´¹èŠ‚ç‚¹é…ç½®æ–‡ä»¶
ä»å¤šä¸ªæºè·å–é…ç½®å¹¶ä¿å­˜
"""

import requests
import yaml
import json
import base64
from datetime import datetime
from pathlib import Path
from urllib.parse import urlparse

# é…ç½®
SOURCES_FILE = "node.txt"
OUTPUT_DIR = "data"
TIMEOUT = 30

def read_sources():
    """ä»é…ç½®æ–‡ä»¶è¯»å–èŠ‚ç‚¹æº"""
    sources_file = Path(SOURCES_FILE)
    if not sources_file.exists():
        print(f"âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {SOURCES_FILE}")
        return []
    
    with open(sources_file, 'r', encoding='utf-8') as f:
        sources = [line.strip() for line in f if line.strip() and line.startswith('http')]
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(sources)} ä¸ªé…ç½®æº")
    return sources

def download_config(url):
    """ä¸‹è½½é…ç½®æ–‡ä»¶"""
    try:
        print(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½: {url}")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=TIMEOUT)
        response.raise_for_status()
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {len(response.text)} å­—èŠ‚")
        return response.text
    except requests.exceptions.Timeout:
        print(f"â±ï¸  ä¸‹è½½è¶…æ—¶: {url}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return None

def is_clash_config(content):
    """åˆ¤æ–­æ˜¯å¦ä¸º Clash é…ç½®"""
    try:
        data = yaml.safe_load(content)
        return isinstance(data, dict) and ('proxies' in data or 'proxy-groups' in data)
    except:
        return False

def is_base64_config(content):
    """åˆ¤æ–­æ˜¯å¦ä¸º Base64 ç¼–ç çš„é…ç½®"""
    try:
        # å°è¯•è§£ç 
        decoded = base64.b64decode(content.strip())
        decoded_str = decoded.decode('utf-8')
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„ä»£ç†åè®®
        return any(protocol in decoded_str for protocol in ['vmess://', 'vless://', 'ss://', 'trojan://'])
    except:
        return False

def save_config(content, filename):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    output_path = Path(OUTPUT_DIR) / filename
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"ğŸ’¾ å·²ä¿å­˜: {filename}")

def process_config(content, index, url):
    """å¤„ç†å¹¶ä¿å­˜é…ç½®æ–‡ä»¶"""
    if not content:
        return None
    
    # åˆ¤æ–­é…ç½®ç±»å‹å¹¶ä¿å­˜
    if is_clash_config(content):
        filename = f"clash_{index}.yml"
        config_type = "Clash"
    elif is_base64_config(content):
        filename = f"v2ray_{index}_base64.txt"
        config_type = "V2Ray (Base64)"
        # åŒæ—¶ä¿å­˜è§£ç åçš„ç‰ˆæœ¬
        try:
            decoded = base64.b64decode(content.strip()).decode('utf-8')
            save_config(decoded, f"v2ray_{index}_decoded.txt")
        except:
            pass
    elif any(protocol in content for protocol in ['vmess://', 'vless://', 'ss://', 'trojan://']):
        filename = f"v2ray_{index}.txt"
        config_type = "V2Ray"
    else:
        filename = f"config_{index}.txt"
        config_type = "Unknown"
    
    save_config(content, filename)
    
    return {
        "index": index,
        "url": url,
        "type": config_type,
        "filename": filename,
        "size": len(content),
        "download_time": datetime.now().isoformat()
    }

def merge_clash_configs(configs):
    """åˆå¹¶å¤šä¸ª Clash é…ç½®"""
    merged = {
        'proxies': [],
        'proxy-groups': [],
        'rules': []
    }
    
    for config_file in Path(OUTPUT_DIR).glob("clash_*.yml"):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                if isinstance(data, dict):
                    if 'proxies' in data:
                        merged['proxies'].extend(data['proxies'])
                    if 'proxy-groups' in data:
                        merged['proxy-groups'].extend(data['proxy-groups'])
                    if 'rules' in data:
                        merged['rules'].extend(data['rules'])
        except Exception as e:
            print(f"âš ï¸  åˆå¹¶é…ç½®å¤±è´¥ {config_file}: {str(e)}")
    
    if merged['proxies']:
        # ä¿å­˜åˆå¹¶åçš„é…ç½®
        merged_file = Path(OUTPUT_DIR) / "clash_merged.yml"
        with open(merged_file, 'w', encoding='utf-8') as f:
            yaml.dump(merged, f, allow_unicode=True, sort_keys=False)
        print(f"ğŸ”— å·²åˆå¹¶ {len(merged['proxies'])} ä¸ªä»£ç†èŠ‚ç‚¹åˆ° clash_merged.yml")

def merge_v2ray_configs():
    """åˆå¹¶å¤šä¸ª V2Ray é…ç½®"""
    all_nodes = []
    
    for config_file in Path(OUTPUT_DIR).glob("v2ray_*.txt"):
        if 'merged' in config_file.name:
            continue
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                # æŒ‰è¡Œåˆ†å‰²èŠ‚ç‚¹
                nodes = [line.strip() for line in content.split('\n') if line.strip()]
                all_nodes.extend(nodes)
        except Exception as e:
            print(f"âš ï¸  è¯»å–é…ç½®å¤±è´¥ {config_file}: {str(e)}")
    
    if all_nodes:
        # å»é‡
        unique_nodes = list(set(all_nodes))
        merged_file = Path(OUTPUT_DIR) / "v2ray_merged.txt"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(unique_nodes))
        print(f"ğŸ”— å·²åˆå¹¶ {len(unique_nodes)} ä¸ªèŠ‚ç‚¹åˆ° v2ray_merged.txt")

def generate_report(results):
    """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
    report = {
        "last_update": datetime.now().isoformat(),
        "total_sources": len(results),
        "successful": sum(1 for r in results if r is not None),
        "failed": sum(1 for r in results if r is None),
        "configs": [r for r in results if r is not None]
    }
    
    report_file = Path(OUTPUT_DIR) / "update_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š æ›´æ–°æŠ¥å‘Š:")
    print(f"   æ€»æºæ•°: {report['total_sources']}")
    print(f"   æˆåŠŸ: {report['successful']}")
    print(f"   å¤±è´¥: {report['failed']}")
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("="*50)
    print(f"ğŸš€ å¼€å§‹æ›´æ–°èŠ‚ç‚¹é…ç½®")
    print(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    
    # è¯»å–é…ç½®æº
    sources = read_sources()
    if not sources:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„é…ç½®æº")
        return
    
    # ä¸‹è½½å¹¶å¤„ç†é…ç½®
    results = []
    for i, url in enumerate(sources, 1):
        print(f"\n[{i}/{len(sources)}] å¤„ç†ä¸­...")
        content = download_config(url)
        result = process_config(content, i, url)
        results.append(result)
    
    # åˆå¹¶é…ç½®
    print(f"\n{'='*50}")
    print("ğŸ”— å¼€å§‹åˆå¹¶é…ç½®æ–‡ä»¶...")
    merge_clash_configs(results)
    merge_v2ray_configs()
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\n{'='*50}")
    generate_report(results)
    
    print(f"\n{'='*50}")
    print("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_DIR}/")
    print("="*50)

if __name__ == "__main__":
    main()

